diff --git a/src/mvs/fusion.cc b/src/mvs/fusion.cc
index 962947a..75d3731 100755
--- a/src/mvs/fusion.cc
+++ b/src/mvs/fusion.cc
@@ -1,3 +1,35 @@
+// ===============================================================================================================
+// Copyright (c) 2019, Cornell University. All rights reserved.
+//
+// Redistribution and use in source and binary forms, with or without modification, are permitted provided that
+// the following conditions are met:
+//
+//     * Redistributions of source code must retain the above copyright otice, this list of conditions and
+//       the following disclaimer.
+//
+//     * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and
+//       the following disclaimer in the documentation and/or other materials provided with the distribution.
+//       
+//     * Neither the name of Cornell University nor the names of its contributors may be used to endorse or
+//       promote products derived from this software without specific prior written permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED 
+// WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDERS OR CONTRIBUTORS BE LIABLE
+// FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
+// HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING 
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY
+// OF SUCH DAMAGE.
+//
+// Author: Kai Zhang (kz298@cornell.edu)
+//
+// The research is based upon work supported by the Office of the Director of National Intelligence (ODNI),     
+// Intelligence Advanced Research Projects Activity (IARPA), via DOI/IBC Contract Number D17PC00287.            
+// The U.S. Government is authorized to reproduce and distribute copies of this work for Governmental purposes. 
+// ===============================================================================================================
+//
+//
 // Copyright (c) 2022, ETH Zurich and UNC Chapel Hill.
 // All rights reserved.
 //
@@ -151,10 +183,10 @@ void StereoFusion::Run() {
 
   auto workspace_format_lower_case = workspace_format_;
   StringToLower(&workspace_format_lower_case);
-  if (workspace_format_lower_case == "pmvs") {
-    workspace_options.stereo_folder =
-        StringPrintf("stereo-%s", pmvs_option_name_.c_str());
-  }
+  // if (workspace_format_lower_case == "pmvs") {
+  //   workspace_options.stereo_folder =
+  //       StringPrintf("stereo-%s", pmvs_option_name_.c_str());
+  // }
 
   workspace_options.num_threads = options_.num_threads;
   workspace_options.max_image_size = options_.max_image_size;
@@ -185,12 +217,12 @@ void StereoFusion::Run() {
   const auto& model = workspace_->GetModel();
 
   const double kMinTriangulationAngle = 0;
-  if (model.GetMaxOverlappingImagesFromPMVS().empty()) {
+  // if (model.GetMaxOverlappingImagesFromPMVS().empty()) {
     overlapping_images_ = model.GetMaxOverlappingImages(
         options_.check_num_images, kMinTriangulationAngle);
-  } else {
-    overlapping_images_ = model.GetMaxOverlappingImagesFromPMVS();
-  }
+  // } else {
+  //   overlapping_images_ = model.GetMaxOverlappingImagesFromPMVS();
+  // }
 
   task_fused_points_.resize(num_threads);
   task_fused_points_visibility_.resize(num_threads);
@@ -202,7 +234,7 @@ void StereoFusion::Run() {
   bitmap_scales_.resize(model.images.size());
   P_.resize(model.images.size());
   inv_P_.resize(model.images.size());
-  inv_R_.resize(model.images.size());
+  // inv_R_.resize(model.images.size());
 
   for (const auto& image_name : image_names) {
     const int image_idx = model.GetImageIdx(image_name);
@@ -232,22 +264,39 @@ void StereoFusion::Run() {
         static_cast<float>(depth_map.GetWidth()) / image.GetWidth(),
         static_cast<float>(depth_map.GetHeight()) / image.GetHeight());
 
-    Eigen::Matrix<float, 3, 3, Eigen::RowMajor> K =
-        Eigen::Map<const Eigen::Matrix<float, 3, 3, Eigen::RowMajor>>(
-            image.GetK());
-    K(0, 0) *= bitmap_scales_.at(image_idx).first;
-    K(0, 2) *= bitmap_scales_.at(image_idx).first;
-    K(1, 1) *= bitmap_scales_.at(image_idx).second;
-    K(1, 2) *= bitmap_scales_.at(image_idx).second;
-
-    ComposeProjectionMatrix(K.data(), image.GetR(), image.GetT(),
-                            P_.at(image_idx).data());
-    ComposeInverseProjectionMatrix(K.data(), image.GetR(), image.GetT(),
-                                   inv_P_.at(image_idx).data());
-    inv_R_.at(image_idx) =
-        Eigen::Map<const Eigen::Matrix<float, 3, 3, Eigen::RowMajor>>(
-            image.GetR())
-            .transpose();
+    // Eigen::Matrix<float, 3, 3, Eigen::RowMajor> K =
+    //     Eigen::Map<const Eigen::Matrix<float, 3, 3, Eigen::RowMajor>>(
+    //         image.GetK());
+    // K(0, 0) *= bitmap_scales_.at(image_idx).first;
+    // K(0, 2) *= bitmap_scales_.at(image_idx).first;
+    // K(1, 1) *= bitmap_scales_.at(image_idx).second;
+    // K(1, 2) *= bitmap_scales_.at(image_idx).second;
+
+    // ComposeProjectionMatrix(K.data(), image.GetR(), image.GetT(),
+    //                         P_.at(image_idx).data());
+    // ComposeInverseProjectionMatrix(K.data(), image.GetR(), image.GetT(),
+    //                                inv_P_.at(image_idx).data());
+    // inv_R_.at(image_idx) =
+    //     Eigen::Map<const Eigen::Matrix<float, 3, 3, Eigen::RowMajor>>(
+    //         image.GetR())
+    //         .transpose();
+
+    //    std::cout << "image_idx: " << image_idx << ", bitmap_scales, first, second: " << bitmap_scales_.at(image_idx).first
+    //        << ", " << bitmap_scales_.at(image_idx).second << std::endl;
+    double K[9];
+    image.GetKDouble(K);
+    K[0] *= bitmap_scales_.at(image_idx).first; // fx
+    K[1] *= bitmap_scales_.at(image_idx).first; // s
+    K[2] *= bitmap_scales_.at(image_idx).first; // cx
+    K[4] *= bitmap_scales_.at(image_idx).second; // fy
+    K[5] *= bitmap_scales_.at(image_idx).second; // cy
+    // pass back to image
+    image.SetK(K);
+
+    // for debug
+    // image.Rotate90Multi_test(0);
+
+    image.GetPinvP(P_.at(image_idx).data(), inv_P_.at(image_idx).data());
   }
 
   std::cout << StringPrintf("Starting fusion with %d threads", num_threads)
@@ -402,7 +451,7 @@ void StereoFusion::Fuse(const int thread_id, const int image_idx, const int row,
     const float depth = depth_map.Get(row, col);
 
     // Pixels with negative depth are filtered.
-    if (depth <= 0.0f) {
+    if (depth <= -1e19f) {
       continue;
     }
 
@@ -410,14 +459,35 @@ void StereoFusion::Fuse(const int thread_id, const int image_idx, const int row,
     // pixel has already been added and we need to check for consistency.
     if (traversal_depth > 0) {
       // Project reference point into current view.
-      const Eigen::Vector3f proj = P_.at(image_idx) * fused_ref_point;
-
-      // Depth error of reference depth with current depth.
-      const float depth_error = std::abs((proj(2) - depth) / depth);
-      if (depth_error > options_.max_depth_error) {
+//      const Eigen::Vector4f proj = P_.at(image_idx) * fused_ref_point;
+//
+//      // Depth error of reference depth with current depth.
+//      // Depth is the inverse of the fourth component
+//      // const float depth_error = std::abs((proj(2)/proj(3) - depth) / depth);
+//
+//      // note that we use the absolute inverse_depth error
+//      const float depth_error = std::abs(proj(3)/proj(2) - 1.f/depth);
+//      if (depth_error > options_.max_depth_error) {
+//        continue;
+//      }
+
+      // check point location
+      const Eigen::Vector4f src_pixel(col, row, 1.0f, depth);
+      const Eigen::Vector4f src_point = inv_P_.at(image_idx) * src_pixel;
+      const Eigen::Vector3f src_point_xyz(src_point(0)/src_point(3),
+                                      src_point(1)/src_point(3),
+                      src_point(2)/src_point(3));
+      const Eigen::Vector3f fused_ref_point_xyz(fused_ref_point(0)/fused_ref_point(3),
+                                            fused_ref_point(1)/fused_ref_point(3),
+                          fused_ref_point(2)/fused_ref_point(3));
+      const Eigen::Vector3f point_diff = fused_ref_point_xyz - src_point_xyz;
+      if (point_diff.norm() > options_.max_depth_error) {
         continue;
       }
 
+      //Project reference point into current view.
+      const Eigen::Vector4f proj = P_.at(image_idx) * fused_ref_point;
+
       // Reprojection error reference point in the current view.
       const float col_diff = proj(0) / proj(2) - col;
       const float row_diff = proj(1) / proj(2) - row;
@@ -429,11 +499,15 @@ void StereoFusion::Fuse(const int thread_id, const int image_idx, const int row,
     }
 
     // Determine normal direction in global reference frame.
+    // Already in the global reference frame
     const auto& normal_map = workspace_->GetNormalMap(image_idx);
-    const Eigen::Vector3f normal =
-        inv_R_.at(image_idx) * Eigen::Vector3f(normal_map.Get(row, col, 0),
-                                               normal_map.Get(row, col, 1),
-                                               normal_map.Get(row, col, 2));
+    const Eigen::Vector3f normal(normal_map.Get(row, col, 0),
+        normal_map.Get(row, col, 1), normal_map.Get(row, col, 2));
+
+//    const Eigen::Vector3f normal =
+//        inv_R_.at(image_idx) * Eigen::Vector3f(normal_map.Get(row, col, 0),
+//                                               normal_map.Get(row, col, 1),
+//                                               normal_map.Get(row, col, 2));
 
     // Check for consistent normal direction with reference normal.
     if (traversal_depth > 0) {
@@ -444,9 +518,13 @@ void StereoFusion::Fuse(const int thread_id, const int image_idx, const int row,
     }
 
     // Determine 3D location of current depth value.
-    const Eigen::Vector3f xyz =
+    // const Eigen::Vector3f xyz =
+    //     inv_P_.at(image_idx) *
+    //     Eigen::Vector4f(col * depth, row * depth, depth, 1.0f);
+    const Eigen::Vector4f xyz_homo =
         inv_P_.at(image_idx) *
-        Eigen::Vector4f(col * depth, row * depth, depth, 1.0f);
+        Eigen::Vector4f(col, row, 1.0f, depth);
+    const Eigen::Vector3f xyz(xyz_homo(0)/xyz_homo(3), xyz_homo(1)/xyz_homo(3), xyz_homo(2)/xyz_homo(3));
 
     // Read the color of the pixel.
     BitmapColor<uint8_t> color;
@@ -499,7 +577,7 @@ void StereoFusion::Fuse(const int thread_id, const int image_idx, const int row,
         continue;
       }
 
-      const Eigen::Vector3f next_proj =
+      const Eigen::Vector4f next_proj =
           P_.at(next_image_idx) * xyz.homogeneous();
       const int next_col =
           static_cast<int>(std::round(next_proj(0) / next_proj(2)));
