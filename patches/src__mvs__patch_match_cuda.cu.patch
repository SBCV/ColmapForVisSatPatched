diff --git a/src/mvs/patch_match_cuda.cu b/src/mvs/patch_match_cuda.cu
index 77d7c73..c415587 100755
--- a/src/mvs/patch_match_cuda.cu
+++ b/src/mvs/patch_match_cuda.cu
@@ -1,3 +1,35 @@
+// ===============================================================================================================
+// Copyright (c) 2019, Cornell University. All rights reserved.
+//
+// Redistribution and use in source and binary forms, with or without modification, are permitted provided that
+// the following conditions are met:
+//
+//     * Redistributions of source code must retain the above copyright otice, this list of conditions and
+//       the following disclaimer.
+//
+//     * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and
+//       the following disclaimer in the documentation and/or other materials provided with the distribution.
+//
+//     * Neither the name of Cornell University nor the names of its contributors may be used to endorse or
+//       promote products derived from this software without specific prior written permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED
+// WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDERS OR CONTRIBUTORS BE LIABLE
+// FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
+// HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY
+// OF SUCH DAMAGE.
+//
+// Author: Kai Zhang (kz298@cornell.edu)
+//
+// The research is based upon work supported by the Office of the Director of National Intelligence (ODNI),
+// Intelligence Advanced Research Projects Activity (IARPA), via DOI/IBC Contract Number D17PC00287.
+// The U.S. Government is authorized to reproduce and distribute copies of this work for Governmental purposes.
+// ===============================================================================================================
+//
+//
 // Copyright (c) 2022, ETH Zurich and UNC Chapel Hill.
 // All rights reserved.
 //
@@ -38,6 +70,7 @@
 #include <cmath>
 #include <cstdint>
 #include <sstream>
+#include <cstdio>
 
 #include "util/cuda.h"
 #include "util/cudacc.h"
@@ -64,10 +97,83 @@ texture<float, cudaTextureType2DLayered, cudaReadModeElementType>
     src_depth_maps_texture;
 texture<float, cudaTextureType2D, cudaReadModeElementType> poses_texture;
 
-// Calibration of reference image as {fx, cx, fy, cy}.
-__constant__ float ref_K[4];
-// Calibration of reference image as {1/fx, -cx/fx, 1/fy, -cy/fy}.
-__constant__ float ref_inv_K[4];
+// Calibration of reference image (first two rows)
+__constant__ float ref_K[6];
+// Calibration of reference image ((first two rows))
+__constant__ float ref_inv_K[6];
+
+// Extrinsics of reference image in the scene coordinate frame
+__constant__ float ref_R[9];
+__constant__ float ref_T[3];
+// projection center of the reference image in the scene coordinate frame
+__constant__ float ref_C[3];
+
+// 4 by 4 projection matrix of reference image and its inverse
+// projection matrices are used to compute inter-image homography
+__constant__ float ref_P[16];
+__constant__ float ref_inv_P[16];
+
+// minimum spatial resolution of these images
+__constant__ float max_dist_per_pixel[1];
+
+
+// homography
+__device__ inline void HomographyWarp(const float mat[9],
+                                      const float vec[2],
+                                      float result[2]) {
+  const float inv_third = 1.0f / (mat[6] * vec[0] + mat[7] * vec[1] + mat[8]);
+  result[0] = inv_third * (mat[0] * vec[0] + mat[1] * vec[1] + mat[2]);
+  result[1] = inv_third * (mat[3] * vec[0] + mat[4] * vec[1] + mat[5]);
+}
+
+// projection
+__device__ inline void Projection(const float mat[16],
+                                  const float vec[3],
+                                  float result[3]) {
+  const float inv_z = 1.0f / (mat[8] * vec[0] + mat[9] * vec[1] + mat[10] * vec[2] + mat[11]);
+  result[0] = inv_z * (mat[0] * vec[0] + mat[1] * vec[1] + mat[2] * vec[2] + mat[3]);
+  result[1] = inv_z * (mat[4] * vec[0] + mat[5] * vec[1] + mat[6] * vec[2] + mat[7]);
+  // depth is now the fourth component
+  result[2] = inv_z * (mat[12] * vec[0] + mat[13] * vec[1] + mat[14] * vec[2] + mat[15]);
+}
+
+// inverse projection
+// depth is now defined as the fourth component
+__device__ inline void InverseProjection(const float mat[16],
+                                         const float vec[3],
+                                         float result[3]) {
+  const float depth = vec[2];
+  const float inv_fourth = 1.0f / (mat[12] * vec[0] + mat[13] * vec[1] + mat[14] + mat[15] * depth);
+  result[0] = inv_fourth * (mat[0] * vec[0] + mat[1] * vec[1] + mat[2] + mat[3] * depth);
+  result[1] = inv_fourth * (mat[4] * vec[0] + mat[5] * vec[1] + mat[6] + mat[7] * depth);
+  result[2] = inv_fourth * (mat[8] * vec[0] + mat[9] * vec[1] + mat[10] + mat[11] * depth);
+}
+
+// note that the returned point is in scene coordinate frame
+// surface normal is also in scene coordinate frame
+__device__ inline void ComputePointAtDepth(const float row, const float col,
+                                           const float depth, float point[3]) {
+  const float vec[3] = {col, row, depth};
+  InverseProjection(ref_inv_P, vec, point);
+  // for debug
+//  printf("computepointatdepth: pixel: %f, %f, %f, point: %f, %f, %f\n", col, row, depth, point[0], point[1], point[2]);
+}
+
+__device__ inline float DotProduct3(const float vec1[3], const float vec2[3]) {
+  return vec1[0] * vec2[0] + vec1[1] * vec2[1] + vec1[2] * vec2[2];
+}
+
+__device__ inline void CrossProduct3(const float vec1[3], const float vec2[3], float result[3]) {
+  result[0] = vec1[1] * vec2[2] - vec1[2] * vec2[1];
+  result[1] = vec1[2] * vec2[0] - vec1[0] * vec2[2];
+  result[2] = vec1[0] * vec2[1] - vec1[1] * vec2[0];
+}
+
+// eucliden distance
+__device__ inline float EuclidDist(const float vec1[3], const float vec2[3]) {
+  const float diff[3] = {vec1[0] - vec2[0], vec1[1] - vec2[1], vec1[2] - vec2[2]};
+  return sqrt(DotProduct3(diff, diff));
+}
 
 __device__ inline void Mat33DotVec3(const float mat[9], const float vec[3],
                                     float result[3]) {
@@ -76,16 +182,47 @@ __device__ inline void Mat33DotVec3(const float mat[9], const float vec[3],
   result[2] = mat[6] * vec[0] + mat[7] * vec[1] + mat[8] * vec[2];
 }
 
-__device__ inline void Mat33DotVec3Homogeneous(const float mat[9],
-                                               const float vec[2],
-                                               float result[2]) {
-  const float inv_z = 1.0f / (mat[6] * vec[0] + mat[7] * vec[1] + mat[8]);
-  result[0] = inv_z * (mat[0] * vec[0] + mat[1] * vec[1] + mat[2]);
-  result[1] = inv_z * (mat[3] * vec[0] + mat[4] * vec[1] + mat[5]);
+//__device__ inline void Mat44DotVec4(const float mat[16], const float vec[4],
+//                                    float result[4]) {
+//  result[0] = mat[0] * vec[0] + mat[1] * vec[1] + mat[2] * vec[2] + mat[3] * vec[3];
+//  result[1] = mat[4] * vec[0] + mat[5] * vec[1] + mat[6] * vec[2] + mat[7] * vec[3];
+//  result[2] = mat[8] * vec[0] + mat[9] * vec[1] + mat[10] * vec[2] + mat[11] * vec[3];
+//  result[3] = mat[12] * vec[0] + mat[13] * vec[1] + mat[14] * vec[2] + mat[15] * vec[3];
+//}
+
+__device__ inline void Vec4DotMat44(const float vec[4], const float mat[16],
+                                    float result[4]) {
+  result[0] = vec[0] * mat[0] + vec[1] * mat[4] + vec[2] * mat[8] + vec[3] * mat[12];
+  result[1] = vec[0] * mat[1] + vec[1] * mat[5] + vec[2] * mat[9] + vec[3] * mat[13];
+  result[2] = vec[0] * mat[2] + vec[1] * mat[6] + vec[2] * mat[10] + vec[3] * mat[14];
+  result[3] = vec[0] * mat[3] + vec[1] * mat[7] + vec[2] * mat[11] + vec[3] * mat[15];
 }
 
-__device__ inline float DotProduct3(const float vec1[3], const float vec2[3]) {
-  return vec1[0] * vec2[0] + vec1[1] * vec2[1] + vec1[2] * vec2[2];
+__device__ inline void Mat44DotMat44(const float mat1[16], const float mat2[16],
+                                     float result[16]) {
+  // first row
+  result[0] = mat1[0] * mat2[0] + mat1[1] * mat2[4] + mat1[2] * mat2[8] + mat1[3] * mat2[12];
+  result[1] = mat1[0] * mat2[1] + mat1[1] * mat2[5] + mat1[2] * mat2[9] + mat1[3] * mat2[13];
+  result[2] = mat1[0] * mat2[2] + mat1[1] * mat2[6] + mat1[2] * mat2[10] + mat1[3] * mat2[14];
+  result[3] = mat1[0] * mat2[3] + mat1[1] * mat2[7] + mat1[2] * mat2[11] + mat1[3] * mat2[15];
+
+  // second row
+  result[4] = mat1[4] * mat2[0] + mat1[5] * mat2[4] + mat1[6] * mat2[8] + mat1[7] * mat2[12];
+  result[5] = mat1[4] * mat2[1] + mat1[5] * mat2[5] + mat1[6] * mat2[9] + mat1[7] * mat2[13];
+  result[6] = mat1[4] * mat2[2] + mat1[5] * mat2[6] + mat1[6] * mat2[10] + mat1[7] * mat2[14];
+  result[7] = mat1[4] * mat2[3] + mat1[5] * mat2[7] + mat1[6] * mat2[11] + mat1[7] * mat2[15];
+
+  // third row
+  result[8] = mat1[8] * mat2[0] + mat1[9] * mat2[4] + mat1[10] * mat2[8] + mat1[11] * mat2[12];
+  result[9] = mat1[8] * mat2[1] + mat1[9] * mat2[5] + mat1[10] * mat2[9] + mat1[11] * mat2[13];
+  result[10] = mat1[8] * mat2[2] + mat1[9] * mat2[6] + mat1[10] * mat2[10] + mat1[11] * mat2[14];
+  result[11] = mat1[8] * mat2[3] + mat1[9] * mat2[7] + mat1[10] * mat2[11] + mat1[11] * mat2[15];
+
+  // fourth row
+  result[12] = mat1[12] * mat2[0] + mat1[13] * mat2[4] + mat1[14] * mat2[8] + mat1[15] * mat2[12];
+  result[13] = mat1[12] * mat2[1] + mat1[13] * mat2[5] + mat1[14] * mat2[9] + mat1[15] * mat2[13];
+  result[14] = mat1[12] * mat2[2] + mat1[13] * mat2[6] + mat1[14] * mat2[10] + mat1[15] * mat2[14];
+  result[15] = mat1[12] * mat2[3] + mat1[13] * mat2[7] + mat1[14] * mat2[11] + mat1[15] * mat2[15];
 }
 
 __device__ inline float GenerateRandomDepth(const float depth_min,
@@ -94,6 +231,7 @@ __device__ inline float GenerateRandomDepth(const float depth_min,
   return curand_uniform(rand_state) * (depth_max - depth_min) + depth_min;
 }
 
+// this might be improved by using non-uniform sampling
 __device__ inline void GenerateRandomNormal(const int row, const int col,
                                             curandState* rand_state,
                                             float normal[3]) {
@@ -113,72 +251,135 @@ __device__ inline void GenerateRandomNormal(const int row, const int col,
   normal[1] = 2.0f * v2 * s_norm;
   normal[2] = 1.0f - 2.0f * s;
 
-  // Make sure normal is looking away from camera.
-  const float view_ray[3] = {ref_inv_K[0] * col + ref_inv_K[1],
-                             ref_inv_K[2] * row + ref_inv_K[3], 1.0f};
-  if (DotProduct3(normal, view_ray) > 0) {
+
+  // make sure normal is pointing towards the camera
+  const float view_ray[3] = {ref_inv_K[0] * col + ref_inv_K[1] * row + ref_inv_K[2],
+                             ref_inv_K[3] * col + ref_inv_K[4] * row + ref_inv_K[5],
+                             1.0f};
+  // rotate view_ray to the scene coordinate frame
+  // need a transpose of R
+  float view_ray_scene[3];
+  const float ref_R_transpose[9] = {ref_R[0], ref_R[3], ref_R[6],
+                                    ref_R[1], ref_R[4], ref_R[7],
+                                    ref_R[2], ref_R[5], ref_R[8]};
+  Mat33DotVec3(ref_R_transpose, view_ray, view_ray_scene);
+
+
+  if (DotProduct3(normal, view_ray_scene) >= 0.0f) {
     normal[0] = -normal[0];
     normal[1] = -normal[1];
     normal[2] = -normal[2];
   }
 }
 
+// make the perturbation more robust to big mean depth
 __device__ inline float PerturbDepth(const float perturbation,
+                                     const float global_depth_min,
+                                     const float global_depth_max,
                                      const float depth,
                                      curandState* rand_state) {
-  const float depth_min = (1.0f - perturbation) * depth;
-  const float depth_max = (1.0f + perturbation) * depth;
-  return GenerateRandomDepth(depth_min, depth_max, rand_state);
+  float depth_min = depth - perturbation * (global_depth_max - global_depth_min);
+  float depth_max = depth + perturbation * (global_depth_max - global_depth_min);
+
+  float depth_new = GenerateRandomDepth(depth_min, depth_max, rand_state);
+  // clamp
+  if (depth_new < global_depth_min) {
+    depth_new = global_depth_min;
+  }
+  if (depth_new > global_depth_max) {
+    depth_new = global_depth_max;
+  }
+
+  return depth_new;
 }
 
+// sampling from a cone that centers around the current normal vector
 __device__ inline void PerturbNormal(const int row, const int col,
-                                     const float perturbation,
+                                     const float max_perturbation_angle,
                                      const float normal[3],
                                      curandState* rand_state,
                                      float perturbed_normal[3],
                                      const int num_trials = 0) {
-  // Perturbation rotation angles.
-  const float a1 = (curand_uniform(rand_state) - 0.5f) * perturbation;
-  const float a2 = (curand_uniform(rand_state) - 0.5f) * perturbation;
-  const float a3 = (curand_uniform(rand_state) - 0.5f) * perturbation;
-
-  const float sin_a1 = sin(a1);
-  const float sin_a2 = sin(a2);
-  const float sin_a3 = sin(a3);
-  const float cos_a1 = cos(a1);
-  const float cos_a2 = cos(a2);
-  const float cos_a3 = cos(a3);
-
-  // R = Rx * Ry * Rz
+
+  // uniformly sample from a cone that centers around the normal vector
+
+  // we first define a local coordinate frame whose z axis aligns with the normal direction
+  // assume the z component of normal is always positive
+  float local_x[3] = {0.0f, normal[2], -normal[1]};
+  // normalize local_x
+  const float inv_local_x_norm = rsqrt(DotProduct3(local_x, local_x));
+  local_x[0] *= inv_local_x_norm;
+  local_x[1] *= inv_local_x_norm;
+  local_x[2] *= inv_local_x_norm;
+  // compute local y direction as z\cross product x
+  float local_y[3];
+  CrossProduct3(normal, local_x, local_y);
+
+  // generate a unit vector on the local x-y plane
+  const float theta = curand_uniform(rand_state) * 2 * M_PI;
+  const float cos_theta = cos(theta);
+  const float sin_theta = sin(theta);
+  // in the local coordinate frame, the vector has coordinate (cos theta, sin theta, 0)
+  // we need to convert it back to the original coordinate frame
+  // note that the rotation from the local coordinate frame to the original one is (local_x, local_y, local_z)
+  const float vec[3] = { cos_theta * local_x[0] + sin_theta * local_y[0],
+                         cos_theta * local_x[1] + sin_theta * local_y[1],
+                         cos_theta * local_x[2] + sin_theta * local_y[2] };
+
+  // compute cross product between vec and normal to get the rotation axis
+  float rot_axis[3];
+  CrossProduct3(vec, normal, rot_axis);
+
+  // sample a perturbation angle around the rotation axis
+  const float alpha = (curand_uniform(rand_state) - 0.5) * 2 * max_perturbation_angle;
+
+  // the rotation matrix in the coordinate frame (vec, normal, rot_axis)
+  //      is (cos alpha, -sin alpha, 0; sin alpha, cos alpha, 0; 0, 0, 1)
+  // we need to represent this rotation in the original coordinate frame
+  // the rotation from (vec, normal, rot_axis) to the original one is (vec, normal, rot_axis)
+  // essentially by multiply (cos alpha, -sin alpha, 0; sin alpha, cos alpha, 0; 0, 0, 1) and
+  //      (vec, normal, rot_axis)^T
   float R[9];
-  R[0] = cos_a2 * cos_a3;
-  R[1] = -cos_a2 * sin_a3;
-  R[2] = sin_a2;
-  R[3] = cos_a1 * sin_a3 + cos_a3 * sin_a1 * sin_a2;
-  R[4] = cos_a1 * cos_a3 - sin_a1 * sin_a2 * sin_a3;
-  R[5] = -cos_a2 * sin_a1;
-  R[6] = sin_a1 * sin_a3 - cos_a1 * cos_a3 * sin_a2;
-  R[7] = cos_a3 * sin_a1 + cos_a1 * sin_a2 * sin_a3;
-  R[8] = cos_a1 * cos_a2;
+  const float cos_alpha = cos(alpha);
+  const float sin_alpha = sin(alpha);
+  R[0] = cos_alpha * vec[0] - sin_alpha * normal[0];
+  R[1] = cos_alpha * vec[1] - sin_alpha * normal[1];
+  R[2] = cos_alpha * vec[2] - sin_alpha * normal[2];
+
+  R[3] = sin_alpha * vec[0] + cos_alpha * normal[0];
+  R[4] = sin_alpha * vec[1] + cos_alpha * normal[1];
+  R[5] = sin_alpha * vec[2] + cos_alpha * normal[2];
+
+  R[6] = rot_axis[0];
+  R[7] = rot_axis[1];
+  R[8] = rot_axis[2];
 
   // Perturb the normal vector.
   Mat33DotVec3(R, normal, perturbed_normal);
 
   // Make sure the perturbed normal is still looking in the same direction as
   // the viewing direction, otherwise try again but with smaller perturbation.
-  const float view_ray[3] = {ref_inv_K[0] * col + ref_inv_K[1],
-                             ref_inv_K[2] * row + ref_inv_K[3], 1.0f};
-  if (DotProduct3(perturbed_normal, view_ray) >= 0.0f) {
+  const float view_ray[3] = {ref_inv_K[0] * col + ref_inv_K[1] * row + ref_inv_K[2],
+                             ref_inv_K[3] * col + ref_inv_K[4] * row + ref_inv_K[5],
+                             1.0f};
+  // rotate view_ray to the reference coordinate frame
+  float view_ray_scene[3];
+  const float ref_R_transpose[9] = {ref_R[0], ref_R[3], ref_R[6],
+                                    ref_R[1], ref_R[4], ref_R[7],
+                                    ref_R[2], ref_R[5], ref_R[8]};
+  Mat33DotVec3(ref_R_transpose, view_ray, view_ray_scene);
+  if (DotProduct3(perturbed_normal, view_ray_scene) >= 0.0f) {
     const int kMaxNumTrials = 3;
     if (num_trials < kMaxNumTrials) {
-      PerturbNormal(row, col, 0.5f * perturbation, normal, rand_state,
+      PerturbNormal(row, col, 0.5f * max_perturbation_angle, normal, rand_state,
                     perturbed_normal, num_trials + 1);
       return;
     } else {
       perturbed_normal[0] = normal[0];
       perturbed_normal[1] = normal[1];
       perturbed_normal[2] = normal[2];
-      return;
+      // @ Sebastian
+      // return;
     }
   }
 
@@ -189,46 +390,49 @@ __device__ inline void PerturbNormal(const int row, const int col,
   perturbed_normal[2] *= inv_norm;
 }
 
-__device__ inline void ComputePointAtDepth(const float row, const float col,
-                                           const float depth, float point[3]) {
-  point[0] = depth * (ref_inv_K[0] * col + ref_inv_K[1]);
-  point[1] = depth * (ref_inv_K[2] * row + ref_inv_K[3]);
-  point[2] = depth;
-}
-
 // Transfer depth on plane from viewing ray at row1 to row2. The returned
 // depth is the intersection of the viewing ray through row2 with the plane
 // at row1 defined by the given depth and normal.
 __device__ inline float PropagateDepth(const float depth1,
-                                       const float normal1[3], const float row1,
+                                       const float normal1[3], const float col, const float row1,
                                        const float row2) {
-  // Point along first viewing ray.
-  const float x1 = depth1 * (ref_inv_K[2] * row1 + ref_inv_K[3]);
-  const float y1 = depth1;
-  // Point on plane defined by point along first viewing ray and plane normal1.
-  const float x2 = x1 + normal1[2];
-  const float y2 = y1 - normal1[1];
-
-  // Origin of second viewing ray.
-  // const float x3 = 0.0f;
-  // const float y3 = 0.0f;
-  // Point on second viewing ray.
-  const float x4 = ref_inv_K[2] * row2 + ref_inv_K[3];
-  // const float y4 = 1.0f;
-
-  // Intersection of the lines ((x1, y1), (x2, y2)) and ((x3, y3), (x4, y4)).
-  const float denom = x2 - x1 + x4 * (y1 - y2);
-  constexpr float kEps = 1e-5f;
-  if (abs(denom) < kEps) {
-    return depth1;
+  // first point
+  float point1[3];
+  ComputePointAtDepth(row1, col, depth1, point1);
+
+  // collect co-efficients for the depth of pixel (col, row2)
+  const float coeff = normal1[0] * (point1[0] * ref_inv_P[15] - ref_inv_P[3]) + \
+                      normal1[1] * (point1[1] * ref_inv_P[15] - ref_inv_P[7]) + \
+                      normal1[2] * (point1[2] * ref_inv_P[15] - ref_inv_P[11]);
+  // collect rhs
+  const float rhs =-( normal1[0] * (point1[0] * (ref_inv_P[12] * col + ref_inv_P[13] * row2 + ref_inv_P[14]) - ref_inv_P[0] * col - ref_inv_P[1] * row2 - ref_inv_P[2]) + \
+                    normal1[1] * (point1[1] * (ref_inv_P[12] * col + ref_inv_P[13] * row2 + ref_inv_P[14]) - ref_inv_P[4] * col - ref_inv_P[5] * row2 - ref_inv_P[6]) + \
+                    normal1[2] * (point1[2] * (ref_inv_P[12] * col + ref_inv_P[13] * row2 + ref_inv_P[14]) - ref_inv_P[8] * col - ref_inv_P[9] * row2 - ref_inv_P[10]) );
+  // depth is now the fourth component
+  float depth2 = rhs / coeff;
+
+  // debug
+//  printf("depth 1: %.6e, depth 2: %.6e\n", depth1, depth2);
+
+  // make sure depth2 is not nan
+  if (depth2 != depth2) {
+    depth2 = depth1;
+  }
+
+  // double check the correctness
+  float point2[3];
+  ComputePointAtDepth(row2, col, depth2, point2);
+  // if we deviate too much from point1, then there's some problem
+  if (EuclidDist(point1, point2) > abs(row2 - row1) * max_dist_per_pixel[0]) {
+    depth2 = depth1;
   }
-  const float nom = y1 * x2 - x1 * y2;
-  return nom / denom;
+  return depth2;
 }
 
 // First, compute triangulation angle between reference and source image for 3D
 // point. Second, compute incident angle between viewing direction of source
 // image and normal direction of 3D point. Both angles are cosine distances.
+// Note that both point and normal coordinates are in scene coordinate frame
 __device__ inline void ComputeViewingAngles(const float point[3],
                                             const float normal[3],
                                             const int image_idx,
@@ -238,80 +442,69 @@ __device__ inline void ComputeViewingAngles(const float point[3],
   *cos_incident_angle = 0.0f;
 
   // Projection center of source image.
-  float C[3];
+  float src_C[3];
   for (int i = 0; i < 3; ++i) {
-    C[i] = tex2D(poses_texture, i + 16, image_idx);
+    src_C[i] = tex2D(poses_texture, i + 32, image_idx);
   }
 
-  // Ray from point to camera.
-  const float SX[3] = {C[0] - point[0], C[1] - point[1], C[2] - point[2]};
+  // Ray from point to reference camera
+  const float RX[3] = {ref_C[0] - point[0], ref_C[1] - point[1], ref_C[2] - point[2]};
+  // Ray from point to source camera
+  const float SX[3] = {src_C[0] - point[0], src_C[1] - point[1], src_C[2] - point[2]};
 
   // Length of ray from reference image to point.
-  const float RX_inv_norm = rsqrt(DotProduct3(point, point));
+  const float RX_inv_norm = rsqrt(DotProduct3(RX, RX));
 
   // Length of ray from source image to point.
   const float SX_inv_norm = rsqrt(DotProduct3(SX, SX));
 
   *cos_incident_angle = DotProduct3(SX, normal) * SX_inv_norm;
-  *cos_triangulation_angle = DotProduct3(SX, point) * RX_inv_norm * SX_inv_norm;
+  *cos_triangulation_angle = DotProduct3(RX, SX) * RX_inv_norm * SX_inv_norm;
 }
 
+// a more numerically stable way to compose homography
 __device__ inline void ComposeHomography(const int image_idx, const int row,
                                          const int col, const float depth,
                                          const float normal[3], float H[9]) {
-  // Calibration of source image.
-  float K[4];
-  for (int i = 0; i < 4; ++i) {
-    K[i] = tex2D(poses_texture, i, image_idx);
+  // Extract projection matrices for source image.
+  float P[16];
+  for (int i = 0; i < 16; ++i) {
+    P[i] = tex2D(poses_texture, i, image_idx);
   }
 
-  // Relative rotation between reference and source image.
-  float R[9];
-  for (int i = 0; i < 9; ++i) {
-    R[i] = tex2D(poses_texture, i + 4, image_idx);
-  }
+  // compute the plane n^Tx+c=0
+  float point[3];
+  ComputePointAtDepth(row, col, depth, point);
+  const float c = -DotProduct3(point, normal);
+
+  // compute the 1 by 4 vector [n; c]^T ref_inv_P
+  float vec_tmp[4];
+  const float plane[4] = {normal[0], normal[1], normal[2], c};
+  Vec4DotMat44(plane, ref_inv_P, vec_tmp);
+
+  // compute matrix P ref_inv_P
+  float mat_tmp[16];
+  Mat44DotMat44(P, ref_inv_P, mat_tmp);
+
+  // the first three components of the fourth column of mat_tmp
+  const float vec_a[3] = {-vec_tmp[0]/vec_tmp[3], -vec_tmp[1]/vec_tmp[3], -vec_tmp[2]/vec_tmp[3]};
+  const float vec_b[3] = {mat_tmp[3], mat_tmp[7], mat_tmp[11]};
+  const float mat_A[9] = {
+      mat_tmp[0], mat_tmp[1], mat_tmp[2],
+      mat_tmp[4], mat_tmp[5], mat_tmp[6],
+      mat_tmp[8], mat_tmp[9], mat_tmp[10]
+  };
 
-  // Relative translation between reference and source image.
-  float T[3];
-  for (int i = 0; i < 3; ++i) {
-    T[i] = tex2D(poses_texture, i + 13, image_idx);
-  }
+  H[0] = mat_A[0] + vec_b[0] * vec_a[0];
+  H[1] = mat_A[1] + vec_b[0] * vec_a[1];
+  H[2] = mat_A[2] + vec_b[0] * vec_a[2];
+  H[3] = mat_A[3] + vec_b[1] * vec_a[0];
+  H[4] = mat_A[4] + vec_b[1] * vec_a[1];
+  H[5] = mat_A[5] + vec_b[1] * vec_a[2];
 
-  // Distance to the plane.
-  const float dist =
-      depth * (normal[0] * (ref_inv_K[0] * col + ref_inv_K[1]) +
-               normal[1] * (ref_inv_K[2] * row + ref_inv_K[3]) + normal[2]);
-  const float inv_dist = 1.0f / dist;
-
-  const float inv_dist_N0 = inv_dist * normal[0];
-  const float inv_dist_N1 = inv_dist * normal[1];
-  const float inv_dist_N2 = inv_dist * normal[2];
-
-  // Homography as H = K * (R - T * n' / d) * Kref^-1.
-  H[0] = ref_inv_K[0] * (K[0] * (R[0] + inv_dist_N0 * T[0]) +
-                         K[1] * (R[6] + inv_dist_N0 * T[2]));
-  H[1] = ref_inv_K[2] * (K[0] * (R[1] + inv_dist_N1 * T[0]) +
-                         K[1] * (R[7] + inv_dist_N1 * T[2]));
-  H[2] = K[0] * (R[2] + inv_dist_N2 * T[0]) +
-         K[1] * (R[8] + inv_dist_N2 * T[2]) +
-         ref_inv_K[1] * (K[0] * (R[0] + inv_dist_N0 * T[0]) +
-                         K[1] * (R[6] + inv_dist_N0 * T[2])) +
-         ref_inv_K[3] * (K[0] * (R[1] + inv_dist_N1 * T[0]) +
-                         K[1] * (R[7] + inv_dist_N1 * T[2]));
-  H[3] = ref_inv_K[0] * (K[2] * (R[3] + inv_dist_N0 * T[1]) +
-                         K[3] * (R[6] + inv_dist_N0 * T[2]));
-  H[4] = ref_inv_K[2] * (K[2] * (R[4] + inv_dist_N1 * T[1]) +
-                         K[3] * (R[7] + inv_dist_N1 * T[2]));
-  H[5] = K[2] * (R[5] + inv_dist_N2 * T[1]) +
-         K[3] * (R[8] + inv_dist_N2 * T[2]) +
-         ref_inv_K[1] * (K[2] * (R[3] + inv_dist_N0 * T[1]) +
-                         K[3] * (R[6] + inv_dist_N0 * T[2])) +
-         ref_inv_K[3] * (K[2] * (R[4] + inv_dist_N1 * T[1]) +
-                         K[3] * (R[7] + inv_dist_N1 * T[2]));
-  H[6] = ref_inv_K[0] * (R[6] + inv_dist_N0 * T[2]);
-  H[7] = ref_inv_K[2] * (R[7] + inv_dist_N1 * T[2]);
-  H[8] = R[8] + ref_inv_K[1] * (R[6] + inv_dist_N0 * T[2]) +
-         ref_inv_K[3] * (R[7] + inv_dist_N1 * T[2]) + inv_dist_N2 * T[2];
+  H[6] = mat_A[6] + vec_b[2] * vec_a[0];
+  H[7] = mat_A[7] + vec_b[2] * vec_a[1];
+  H[8] = mat_A[8] + vec_b[2] * vec_a[2];
 }
 
 // Each thread in the current warp / thread block reads in 3 columns of the
@@ -419,7 +612,7 @@ struct PhotoConsistencyCostComputer {
   int col = -1;
 
   // Depth and normal for which to warp patch.
-  float depth = 0.0f;
+  float depth = -1e20f;
   const float* normal = nullptr;
 
   __device__ inline void Read(const int row) {
@@ -464,7 +657,7 @@ struct PhotoConsistencyCostComputer {
     for (int row = -kWindowRadius; row <= kWindowRadius; row += kWindowStep) {
       for (int col = -kWindowRadius; col <= kWindowRadius; col += kWindowStep) {
         const float inv_z = 1.0f / z;
-        const float norm_col_src = inv_z * col_src + 0.5f;
+        const float norm_col_src = inv_z * col_src + 0.5f;  // half pixel is due to GPU's texture memory
         const float norm_row_src = inv_z * row_src + 0.5f;
         const float ref_color = local_ref_image.data[ref_image_idx];
         const float src_color = tex2DLayered(src_images_texture, norm_col_src,
@@ -531,19 +724,20 @@ struct PhotoConsistencyCostComputer {
   const BilateralWeightComputer bilateral_weight_computer_;
 };
 
+// important
 __device__ inline float ComputeGeomConsistencyCost(const float row,
                                                    const float col,
                                                    const float depth,
                                                    const int image_idx,
                                                    const float max_cost) {
   // Extract projection matrices for source image.
-  float P[12];
-  for (int i = 0; i < 12; ++i) {
-    P[i] = tex2D(poses_texture, i + 19, image_idx);
+  float P[16];
+  for (int i = 0; i < 16; ++i) {
+    P[i] = tex2D(poses_texture, i, image_idx);
   }
-  float inv_P[12];
-  for (int i = 0; i < 12; ++i) {
-    inv_P[i] = tex2D(poses_texture, i + 31, image_idx);
+  float inv_P[16];
+  for (int i = 0; i < 16; ++i) {
+    inv_P[i] = tex2D(poses_texture, i + 16, image_idx);
   }
 
   // Project point in reference image to world.
@@ -551,48 +745,32 @@ __device__ inline float ComputeGeomConsistencyCost(const float row,
   ComputePointAtDepth(row, col, depth, forward_point);
 
   // Project world point to source image.
-  const float inv_forward_z =
-      1.0f / (P[8] * forward_point[0] + P[9] * forward_point[1] +
-              P[10] * forward_point[2] + P[11]);
-  float src_col =
-      inv_forward_z * (P[0] * forward_point[0] + P[1] * forward_point[1] +
-                       P[2] * forward_point[2] + P[3]);
-  float src_row =
-      inv_forward_z * (P[4] * forward_point[0] + P[5] * forward_point[1] +
-                       P[6] * forward_point[2] + P[7]);
+  float src_pixel[2];
+  Projection(P, forward_point, src_pixel);
 
   // Extract depth in source image.
-  const float src_depth = tex2DLayered(src_depth_maps_texture, src_col + 0.5f,
-                                       src_row + 0.5f, image_idx);
+  // why would we need a half pixel here
+  const float src_depth = tex2DLayered(src_depth_maps_texture, src_pixel[0] + 0.5f,
+                                       src_pixel[1] + 0.5f, image_idx);
 
   // Projection outside of source image.
-  if (src_depth == 0.0f) {
+  if (src_depth <= -1e19f) {
     return max_cost;
   }
 
   // Project point in source image to world.
-  src_col *= src_depth;
-  src_row *= src_depth;
-  const float backward_point_x =
-      inv_P[0] * src_col + inv_P[1] * src_row + inv_P[2] * src_depth + inv_P[3];
-  const float backward_point_y =
-      inv_P[4] * src_col + inv_P[5] * src_row + inv_P[6] * src_depth + inv_P[7];
-  const float backward_point_z = inv_P[8] * src_col + inv_P[9] * src_row +
-                                 inv_P[10] * src_depth + inv_P[11];
-  const float inv_backward_point_z = 1.0f / backward_point_z;
+  float backward_point[3];
+  const float src_pixel_depth[3] = {src_pixel[0], src_pixel[1], src_depth};
+  InverseProjection(inv_P, src_pixel_depth, backward_point);
 
   // Project world point back to reference image.
-  const float backward_col =
-      inv_backward_point_z *
-      (ref_K[0] * backward_point_x + ref_K[1] * backward_point_z);
-  const float backward_row =
-      inv_backward_point_z *
-      (ref_K[2] * backward_point_y + ref_K[3] * backward_point_z);
+  float ref_pixel[2];
+  Projection(ref_P, backward_point, ref_pixel);
 
   // Return truncated reprojection error between original observation and
   // the forward-backward projected observation.
-  const float diff_col = col - backward_col;
-  const float diff_row = row - backward_row;
+  const float diff_col = col - ref_pixel[0];
+  const float diff_row = row - ref_pixel[1];
   return min(max_cost, sqrt(diff_col * diff_col + diff_row * diff_row));
 }
 
@@ -695,16 +873,16 @@ class LikelihoodComputer {
     // Warp corners of patch in reference image to source image.
     float src1[2];
     const float ref1[2] = {col - kWindowRadius, row - kWindowRadius};
-    Mat33DotVec3Homogeneous(H, ref1, src1);
+    HomographyWarp(H, ref1, src1);
     float src2[2];
     const float ref2[2] = {col - kWindowRadius, row + kWindowRadius};
-    Mat33DotVec3Homogeneous(H, ref2, src2);
+    HomographyWarp(H, ref2, src2);
     float src3[2];
     const float ref3[2] = {col + kWindowRadius, row + kWindowRadius};
-    Mat33DotVec3Homogeneous(H, ref3, src3);
+    HomographyWarp(H, ref3, src3);
     float src4[2];
     const float ref4[2] = {col + kWindowRadius, row - kWindowRadius};
-    Mat33DotVec3Homogeneous(H, ref4, src4);
+    HomographyWarp(H, ref4, src4);
 
     // Compute area of patches in reference and source image.
     const float ref_area = kWindowSize * kWindowSize;
@@ -761,7 +939,6 @@ class LikelihoodComputer {
   float ncc_norm_factor_;
 };
 
-// Rotate normals by 90deg around z-axis in counter-clockwise direction.
 __global__ void InitNormalMap(GpuMat<float> normal_map,
                               GpuMat<curandState> rand_state_map) {
   const int row = blockDim.y * blockIdx.y + threadIdx.y;
@@ -775,21 +952,6 @@ __global__ void InitNormalMap(GpuMat<float> normal_map,
   }
 }
 
-// Rotate normals by 90deg around z-axis in counter-clockwise direction.
-__global__ void RotateNormalMap(GpuMat<float> normal_map) {
-  const int row = blockDim.y * blockIdx.y + threadIdx.y;
-  const int col = blockDim.x * blockIdx.x + threadIdx.x;
-  if (col < normal_map.GetWidth() && row < normal_map.GetHeight()) {
-    float normal[3];
-    normal_map.GetSlice(row, col, normal);
-    float rotated_normal[3];
-    rotated_normal[0] = normal[1];
-    rotated_normal[1] = -normal[0];
-    rotated_normal[2] = normal[2];
-    normal_map.SetSlice(row, col, rotated_normal);
-  }
-}
-
 template <int kWindowSize, int kWindowStep>
 __global__ void ComputeInitialCost(GpuMat<float> cost_map,
                                    const GpuMat<float> depth_map,
@@ -913,7 +1075,7 @@ __global__ void SweepFromTopToBottom(
   pcc_computer.local_ref_image.data = &local_ref_image_data[0];
 
   struct ParamState {
-    float depth = 0.0f;
+    float depth = -1e20f;  // absurd value
     float normal[3] = {0};
   };
 
@@ -952,7 +1114,7 @@ __global__ void SweepFromTopToBottom(
     // the depth of very oblique structures, i.e. pixels whose normal direction
     // is significantly different from their viewing direction.
     prev_param_state.depth = PropagateDepth(
-        prev_param_state.depth, prev_param_state.normal, row - 1, row);
+        prev_param_state.depth, prev_param_state.normal, col, row - 1, row);
 
     // Read parameters for current pixel from previous sweep.
     curr_param_state.depth = depth_map.Get(row, col);
@@ -960,7 +1122,7 @@ __global__ void SweepFromTopToBottom(
 
     // Generate random parameters.
     rand_param_state.depth =
-        PerturbDepth(options.perturbation, curr_param_state.depth, &rand_state);
+        PerturbDepth(options.perturbation, options.depth_min, options.depth_max, curr_param_state.depth, &rand_state);
     PerturbNormal(row, col, options.perturbation * M_PI,
                   curr_param_state.normal, &rand_state,
                   rand_param_state.normal);
@@ -1104,7 +1266,9 @@ __global__ void SweepFromTopToBottom(
         float cos_incident_angle;
         ComputeViewingAngles(best_point, best_normal, image_idx,
                              &cos_triangulation_angle, &cos_incident_angle);
-        if (cos_triangulation_angle > cos_min_triangulation_angle ||
+        // triangulation angle should not be too big or too small
+        // which is why we need to take the absolute value
+        if (abs(cos_triangulation_angle) > cos_min_triangulation_angle ||
             cos_incident_angle <= 0.0f) {
           continue;
         }
@@ -1133,10 +1297,11 @@ __global__ void SweepFromTopToBottom(
       }
 
       if (num_consistent < options.filter_min_num_consistent) {
-        depth_map.Set(row, col, 0.0f);
-        normal_map.Set(row, col, 0, 0.0f);
-        normal_map.Set(row, col, 1, 0.0f);
-        normal_map.Set(row, col, 2, 0.0f);
+        const float kFilterValue = -1e20f;
+        depth_map.Set(row, col, kFilterValue);
+        normal_map.Set(row, col, 0, kFilterValue);
+        normal_map.Set(row, col, 1, kFilterValue);
+        normal_map.Set(row, col, 2, kFilterValue);
         for (int image_idx = 0; image_idx < cost_map.GetDepth(); ++image_idx) {
           consistency_mask.Set(row, col, image_idx, 0);
         }
@@ -1170,9 +1335,7 @@ PatchMatchCuda::PatchMatchCuda(const PatchMatchOptions& options,
 }
 
 PatchMatchCuda::~PatchMatchCuda() {
-  for (size_t i = 0; i < 4; ++i) {
-    poses_device_[i].reset();
-  }
+  poses_device_.reset();
 }
 
 void PatchMatchCuda::Run() {
@@ -1318,6 +1481,11 @@ void PatchMatchCuda::RunWithWindowSizeAndStep() {
 
       const bool last_sweep = iter == options_.num_iterations - 1 && sweep == 3;
 
+//      printf("\nsweep: %i", sweep);
+//      int numBlock = 1;
+//      int numThreadsPerBlock = 1;
+//      PrintSetting<<<numBlock,numThreadsPerBlock>>>();
+
 #define CALL_SWEEP_FUNC                                                  \
   SweepFromTopToBottom<kWindowSize, kWindowStep, kGeomConsistencyTerm,   \
                        kFilterPhotoConsistency, kFilterGeomConsistency>  \
@@ -1487,7 +1655,8 @@ void PatchMatchCuda::InitSourceImages() {
 
   // Upload source depth maps to device.
   if (options_.geom_consistency) {
-    const float kDefaultValue = 0.0f;
+    // change default value to an absurd one
+    const float kDefaultValue = -1e20f;
     std::vector<float> src_depth_maps_host_data(
         static_cast<size_t>(max_width * max_height *
                             problem_.src_image_idxs.size()),
@@ -1527,107 +1696,85 @@ void PatchMatchCuda::InitTransforms() {
   // Generate rotated versions (counter-clockwise) of calibration matrix.
   //////////////////////////////////////////////////////////////////////////////
 
-  for (size_t i = 0; i < 4; ++i) {
-    ref_K_host_[i][0] = ref_image.GetK()[0];
-    ref_K_host_[i][1] = ref_image.GetK()[2];
-    ref_K_host_[i][2] = ref_image.GetK()[4];
-    ref_K_host_[i][3] = ref_image.GetK()[5];
+  for (int i = 0; i < 4; ++i) {
+    float K_full_tmp[9];
+    float inv_K_full_tmp[9];
+    ref_image.Rotate90Multi(i, K_full_tmp, inv_K_full_tmp, ref_R_host_[i], ref_T_host_[i], ref_P_host_[i], ref_inv_P_host_[i], ref_C_host_);
+    ref_K_host_[i][0] = K_full_tmp[0];
+    ref_K_host_[i][1] = K_full_tmp[1];
+    ref_K_host_[i][2] = K_full_tmp[2];
+    ref_K_host_[i][3] = K_full_tmp[3];
+    ref_K_host_[i][4] = K_full_tmp[4];
+    ref_K_host_[i][5] = K_full_tmp[5];
+
+    ref_inv_K_host_[i][0] = inv_K_full_tmp[0];
+    ref_inv_K_host_[i][1] = inv_K_full_tmp[1];
+    ref_inv_K_host_[i][2] = inv_K_full_tmp[2];
+    ref_inv_K_host_[i][3] = inv_K_full_tmp[3];
+    ref_inv_K_host_[i][4] = inv_K_full_tmp[4];
+    ref_inv_K_host_[i][5] = inv_K_full_tmp[5];
   }
 
-  // Rotated by 90 degrees.
-  std::swap(ref_K_host_[1][0], ref_K_host_[1][2]);
-  std::swap(ref_K_host_[1][1], ref_K_host_[1][3]);
-  ref_K_host_[1][3] = ref_width_ - 1 - ref_K_host_[1][3];
-
-  // Rotated by 180 degrees.
-  ref_K_host_[2][1] = ref_width_ - 1 - ref_K_host_[2][1];
-  ref_K_host_[2][3] = ref_height_ - 1 - ref_K_host_[2][3];
-
-  // Rotated by 270 degrees.
-  std::swap(ref_K_host_[3][0], ref_K_host_[3][2]);
-  std::swap(ref_K_host_[3][1], ref_K_host_[3][3]);
-  ref_K_host_[3][1] = ref_height_ - 1 - ref_K_host_[3][1];
-
-  // Extract 1/fx, -cx/fx, fy, -cy/fy.
-  for (size_t i = 0; i < 4; ++i) {
-    ref_inv_K_host_[i][0] = 1.0f / ref_K_host_[i][0];
-    ref_inv_K_host_[i][1] = -ref_K_host_[i][1] / ref_K_host_[i][0];
-    ref_inv_K_host_[i][2] = 1.0f / ref_K_host_[i][2];
-    ref_inv_K_host_[i][3] = -ref_K_host_[i][3] / ref_K_host_[i][2];
-  }
+  //max_dist_per_pixel = max_dist_per_pixel_host_;
+  CUDA_SAFE_CALL(cudaMemcpyToSymbol(max_dist_per_pixel, &max_dist_per_pixel_host_, sizeof(float), 0,
+                                    cudaMemcpyHostToDevice));
+  // copy
+  CUDA_SAFE_CALL(cudaMemcpyToSymbol(ref_C, ref_C_host_, sizeof(float) * 3, 0, cudaMemcpyHostToDevice));
 
   // Bind 0 degrees version to constant global memory.
-  CUDA_SAFE_CALL(cudaMemcpyToSymbol(ref_K, ref_K_host_[0], sizeof(float) * 4, 0,
+  CUDA_SAFE_CALL(cudaMemcpyToSymbol(ref_K, ref_K_host_[0], sizeof(float) * 6, 0, cudaMemcpyHostToDevice));
+  CUDA_SAFE_CALL(cudaMemcpyToSymbol(ref_inv_K, ref_inv_K_host_[0], sizeof(float) * 6, 0, cudaMemcpyHostToDevice));
+  CUDA_SAFE_CALL(cudaMemcpyToSymbol(ref_R, ref_R_host_[0], sizeof(float) * 9, 0,
+                                    cudaMemcpyHostToDevice));
+  CUDA_SAFE_CALL(cudaMemcpyToSymbol(ref_T, ref_T_host_[0],
+                                    sizeof(float) * 3, 0,
                                     cudaMemcpyHostToDevice));
-  CUDA_SAFE_CALL(cudaMemcpyToSymbol(ref_inv_K, ref_inv_K_host_[0],
-                                    sizeof(float) * 4, 0,
+  CUDA_SAFE_CALL(cudaMemcpyToSymbol(ref_P, ref_P_host_[0],
+                                    sizeof(float) * 16, 0,
+                                    cudaMemcpyHostToDevice));
+  CUDA_SAFE_CALL(cudaMemcpyToSymbol(ref_inv_P, ref_inv_P_host_[0],
+                                    sizeof(float) * 16, 0,
                                     cudaMemcpyHostToDevice));
 
   //////////////////////////////////////////////////////////////////////////////
-  // Generate rotated versions of camera poses.
+  // Upload P, inv_P, C for source images
   //////////////////////////////////////////////////////////////////////////////
+  const size_t kNumTformParams = 16 + 16 + 3;
+  float poses_host_data[kNumTformParams * problem_.src_image_idxs.size()];
 
-  float rotated_R[9];
-  memcpy(rotated_R, ref_image.GetR(), 9 * sizeof(float));
-
-  float rotated_T[3];
-  memcpy(rotated_T, ref_image.GetT(), 3 * sizeof(float));
-
-  // Matrix for 90deg rotation around Z-axis in counter-clockwise direction.
-  const float R_z90[9] = {0, 1, 0, -1, 0, 0, 0, 0, 1};
-
-  for (size_t i = 0; i < 4; ++i) {
-    const size_t kNumTformParams = 4 + 9 + 3 + 3 + 12 + 12;
-    std::vector<float> poses_host_data(kNumTformParams *
-                                       problem_.src_image_idxs.size());
-    int offset = 0;
-    for (const auto image_idx : problem_.src_image_idxs) {
-      const Image& image = problem_.images->at(image_idx);
-
-      const float K[4] = {image.GetK()[0], image.GetK()[2], image.GetK()[4],
-                          image.GetK()[5]};
-      memcpy(poses_host_data.data() + offset, K, 4 * sizeof(float));
-      offset += 4;
-
-      float rel_R[9];
-      float rel_T[3];
-      ComputeRelativePose(rotated_R, rotated_T, image.GetR(), image.GetT(),
-                          rel_R, rel_T);
-      memcpy(poses_host_data.data() + offset, rel_R, 9 * sizeof(float));
-      offset += 9;
-      memcpy(poses_host_data.data() + offset, rel_T, 3 * sizeof(float));
-      offset += 3;
-
-      float C[3];
-      ComputeProjectionCenter(rel_R, rel_T, C);
-      memcpy(poses_host_data.data() + offset, C, 3 * sizeof(float));
-      offset += 3;
-
-      float P[12];
-      ComposeProjectionMatrix(image.GetK(), rel_R, rel_T, P);
-      memcpy(poses_host_data.data() + offset, P, 12 * sizeof(float));
-      offset += 12;
-
-      float inv_P[12];
-      ComposeInverseProjectionMatrix(image.GetK(), rel_R, rel_T, inv_P);
-      memcpy(poses_host_data.data() + offset, inv_P, 12 * sizeof(float));
-      offset += 12;
-    }
-
-    poses_device_[i].reset(new CudaArrayWrapper<float>(
-        kNumTformParams, problem_.src_image_idxs.size(), 1));
-    poses_device_[i]->CopyToDevice(poses_host_data.data());
-
-    RotatePose(R_z90, rotated_R, rotated_T);
+  int offset = 0;
+  for (const auto image_idx : problem_.src_image_idxs) {
+    const Image &image = problem_.images->at(image_idx);
+
+    float K_full[9];
+    float inv_K_full[9];
+    float R[9];
+    float T[3];
+    float P[16];
+    float inv_P[16];
+    float C[3];
+
+    // because the point is in scene coorindaste frame, hence we should not rotate source images
+    image.Original(K_full, inv_K_full, R, T, P, inv_P, C);
+
+    memcpy(poses_host_data + offset, P, 16 * sizeof(float));
+    offset += 16;
+    memcpy(poses_host_data + offset, inv_P, 16 * sizeof(float));
+    offset += 16;
+    memcpy(poses_host_data + offset, C, 3 * sizeof(float));
+    offset += 3;
   }
 
+  poses_device_.reset(new CudaArrayWrapper<float>(
+      kNumTformParams, problem_.src_image_idxs.size(), 1));
+  poses_device_->CopyToDevice(poses_host_data);
+
   poses_texture.addressMode[0] = cudaAddressModeBorder;
   poses_texture.addressMode[1] = cudaAddressModeBorder;
   poses_texture.addressMode[2] = cudaAddressModeBorder;
   poses_texture.filterMode = cudaFilterModePoint;
   poses_texture.normalized = false;
-  CUDA_SAFE_CALL(
-      cudaBindTextureToArray(poses_texture, poses_device_[0]->GetPtr()));
+  CUDA_SAFE_CALL(cudaBindTextureToArray(poses_texture, poses_device_->GetPtr()));
 }
 
 void PatchMatchCuda::InitWorkspaceMemory() {
@@ -1710,8 +1857,6 @@ void PatchMatchCuda::Rotate() {
 
   // Rotate normal map.
   {
-    RotateNormalMap<<<elem_wise_grid_size_, elem_wise_block_size_>>>(
-        *normal_map_);
     std::unique_ptr<GpuMat<float>> rotated_normal_map(
         new GpuMat<float>(width, height, 3));
     normal_map_->Rotate(rotated_normal_map.get());
@@ -1751,18 +1896,31 @@ void PatchMatchCuda::Rotate() {
     cost_map_.swap(rotated_cost_map);
   }
 
-  // Rotate transformations.
-  CUDA_SAFE_CALL(cudaUnbindTexture(poses_texture));
-  CUDA_SAFE_CALL(cudaBindTextureToArray(
-      poses_texture, poses_device_[rotation_in_half_pi_]->GetPtr()));
-
   // Rotate calibration.
   CUDA_SAFE_CALL(cudaMemcpyToSymbol(ref_K, ref_K_host_[rotation_in_half_pi_],
-                                    sizeof(float) * 4, 0,
+                                    sizeof(float) * 6, 0,
                                     cudaMemcpyHostToDevice));
   CUDA_SAFE_CALL(
       cudaMemcpyToSymbol(ref_inv_K, ref_inv_K_host_[rotation_in_half_pi_],
-                         sizeof(float) * 4, 0, cudaMemcpyHostToDevice));
+                         sizeof(float) * 6, 0, cudaMemcpyHostToDevice));
+
+  // Rotate extrinsics
+  CUDA_SAFE_CALL(
+      cudaMemcpyToSymbol(ref_R, ref_R_host_[rotation_in_half_pi_],
+                         sizeof(float) * 9, 0, cudaMemcpyHostToDevice));
+  CUDA_SAFE_CALL(
+      cudaMemcpyToSymbol(ref_T, ref_T_host_[rotation_in_half_pi_],
+                         sizeof(float) * 3, 0, cudaMemcpyHostToDevice));
+
+  // Rotate Projection Matrix
+  CUDA_SAFE_CALL(
+      cudaMemcpyToSymbol(ref_P, ref_P_host_[rotation_in_half_pi_],
+                         sizeof(float) * 16, 0,
+                         cudaMemcpyHostToDevice));
+  CUDA_SAFE_CALL(
+      cudaMemcpyToSymbol(ref_inv_P, ref_inv_P_host_[rotation_in_half_pi_],
+                         sizeof(float) * 16, 0,
+                         cudaMemcpyHostToDevice));
 
   // Recompute Cuda configuration for rotated reference image.
   ComputeCudaConfig();
